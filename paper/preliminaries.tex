\section{Terminology, Notation and Problem Definition}

Throughout this paper, we use the term \emph{reference date} for the date $t$ to which a particular quantity refers, and the term \emph{report date} for the date $s$ in which a particular quantity became available to the model.

Let $Y_{it}$ denote a surveillance value associated with the \emph{reference date} $t$ for location $i$. The time series ${Y_{it}}{t \in T}$ represents the usual uni-variate surveillance data for location $i$, where $T$ denotes a set of reference dates. The value of $Y_{it}$ reported as of date $s$ ($s \ge t$) is denoted by $Y_{itl}$, where $l$ is the \emph{lag}, defined as $l = s - t \in \mathbf{N}$, representing the number of days between the report date $s$ and the reference date $t$. By convention, $l \ge 0$. The value $Y_{itl}$ corresponds to the $(l+1)$th version of $Y_{it}$ (with $l=0$ representing the initial release).

\paragraph{Revision Dynamics:} Due to the existence of data revision, each $Y_{it}$ has its \emph{data revision sequence} $Y_{it}^{t:s}$ as of date $s$, equivalently denoted by $Y_{it,0:(s-t)}$. Only a minimal portion of data revision results from instances where data is initially lost but subsequently recovered, or when data is initially entered incorrectly but corrected later. The predominant share of data revision is usually results from reporting delays. The data revision sequence $Y_{itl}$ tends to asymptote as $l$ approaches a sufficiently large value $L_{it}$. We call $L_{it}$ the \emph{target lag}, and $Y_{itL_{it}}$ is called the target value of $Y_{it}$. 

To reduce confusion, $Y_{itl}$ represents the most up-to-date version of $Y_{it}$ as of date $s = t+l$ regardless of whether a revision or a report action occurred on date $s$.  It is important to distinguish between \emph{no reported revision} and \emph{a report of no revision}. In cases where a revision occurs but is not reported, this scenario is categorized as no reported revision. In this paper, we pragmatically assume that no reported revision is equivalent to a report of no revision, as the distinction is not recorded in the data available to us. Namely, when there is no report for $Y_{itl}$, we define 
$$
    Y_{itl}=
\begin{cases}
    0,           & \text{if } l = 0\\
    Y_{it(l-1)}, & \text{if } l\geq 1\\    
\end{cases}
$$
We then uniformly refer to $Y_{itl}$ as the $(l+1)$th release (or the $l$th revision) of $Y_{it}$.

% We refer to $Y_{it}=Y_{it\infty}$ as the \emph{finalized} surveillance value.
%% Roni: Y_}it\infty} is a problematic concept, because the reporting sequence is always finite.  Above we defined "finalized value" as Y_{itL}.
%% Jingjing: Later on, we decided to give up the term "finalized" to reduce confusion.

\paragraph{Problem Setup:}
In practice, the time required for the convergence of the revision exhibits considerable variability across different data streams, locations $i$ and reference dates $t$, and can be exceptionally large. Figure S1 (in the Appendix) provides an illustration in which, for COVID-19 claims reports with a reference date of 2021-08-01, most states require more than 180 days (approximately half a year) for the data revision sequences to converge. 

However, such values of \( L_{it} \) are not available in real-time since it is impossible to determine whether the revision for \( Y_{it} \) has been finalized. This creates a challenge in selecting the target value corresponding to a target horizon \( L_{it} \) for \( Y_{it} \). On one hand, we prefer a long target horizon to ensure that the reporting sequence has asymptoted or is close to asymptoting. We aim for greater accuracy, which means that we tend to select a target lag \( L_{it} \) that is large enough to ensure that the estimates closely approximate the value to which \( Y_{it} \) asymptotes. On the other hand, we want our model to remain adaptive. Data revision dynamics evolve over time, and training on outdated data could result in model mismatch or bias. Selecting a larger lag \( L_{it} \) limits the model to data from \( L_{it} \) days ago, whereas a smaller lag allows the model to respond more effectively to recent changes in the data.

The selection of the target lag involves a trade-off between accuracy and adaptability. To address this, we choose a fixed target lag \( L \) for all reference dates and locations that captures the majority of revisions (e.g., 90\% of case counts reported) after exploring the available revision history of a public health data stream. Additionally, we ensure that the target lag does not exceed 60 days to maintain the model's adaptability.

Given a revision sequence $Y_{it, 0:l}$, our goal is to provide a distributional estimate of the target $Y_{itL}$ for a suitably large $L$ in the form of a set of quantile estimates $Q_{Y_{itL}}^{\tau}$ for a pre-determined set of quantiles $\tau$s. 








