\section{Methods}
In this section, we introduce a non-parametric model, Delphi Revision Forecast (Delphi-RF), which leverages quantile regression to characterize the dynamics of data revisions. Let $L$ denote the target lag. For a random variable $Y_{itl}$ representing the value for location $i$ and reference date $t$, as reported at time $t + l$, the corresponding target is $Y_{itL}$. We denote the cumulative distribution function of $Y_{itL}$ as
\[
F_{Y_{itL}}(y) = P(Y_{itL} \leq y).
\]
The $\tau$th quantile of $Y_{itL}$ is defined as
\[
Q_{Y_{itL}}^{\tau} = \inf \left\{ y : F_{Y_{itL}}(y) \geq \tau \right\}, \quad \tau \in (0, 1).
\]

Given the potential nonlinear effects of calendar factors such as day-of-week and week-of-month, and motivated by the objective of minimizing relative error between estimates and targets, we adopt a multiplicative model to estimate the conditional quantiles of the log-transformed target. To avoid undefined values when reported counts are zero, we apply a natural logarithmic transformation, defined as $f(x) = \log(x + 1)$, to all relevant quantities. Since $f(\cdot)$ is a monotonically increasing function, the quantile of the transformed target equals the transformed quantile of the target:
\[
Q_{f(Y_{itL})}^{\tau} = f\left(Q_{Y_{itL}}^{\tau}\right).
\]

At any given estimation date (a report date) $s_0$, our goal is to make distributional estimates of $Y_{itL}$ for all reference date $t \in (s_0-L, s_0]$ based on data that is available as of date $s_0$. To simplify notation, we use $f(Y_{itL})|X_{itl}$ to represent $f(Y_{itL})$ as conditioned on the feature vector $X_{itl}$, which is based on $\{Y_{itl}\}_{t+l \leq s_0, l\in [0, L)}$. Therefore, our model is 
\begin{align*} 
Q_{f(Y_{itL})|X_{itl}}^{\tau} &=  X_{itl}\beta^{\tau}
\end{align*}

We incorporate features to account for week-of-month effects based on report dates, as well as day-of-week effects based on both report dates and reference dates. To capture week-of-month effects, we use the indicator \( \mathbf{I}_{\text{first-week}(t)} \), which identifies whether a given date \( t \) falls within the first week of a month, where each week begins on a Sunday. If date \( t \) corresponds to the final days of a month and overlaps both the fifth week of the current month and the first week of the subsequent month, it is still classified as part of the first week. For day-of-week effects, we define the vector \( \mathbf{e}_{wd(t)} \) as a one-hot encoded vector, where the first element is set to 0 if \( t \) is a Monday, 1 if \( t \) falls on a weekend, and 2 otherwise. To ensure model identifiability, we omit one category from each of the two one-hot encoded feature sets.

We incorporate two features to represent disease activity levels.  The first one is the 7day moving average of the current reports. Let \( \widetilde{Y}_{itl} \) denote the 7-day moving average of values reported with report date \( t + l \), defined as

\[
\widetilde{Y}_{itl} = \sum_{v=0}^{6} Y_{i(t - v)(l + v)}.
\] 
Given the significant skewness in \( Y_{itl} \), we apply a square root transformation to improve linearity between the quantiles and the transformed variable. We then construct a one-hot encoded vector \( \mathbf{e}_{\sqrt{\widetilde{Y}_{itl}}} \), whose components correspond to four equal-width bins of \( \sqrt{\widetilde{Y}_{itl}} \), determined based on its empirical distribution in the training data. To ensure identifiability, only three of the four indicator variables are included in the model. In practice, to mitigate instability arising from sparsely populated bins—particularly in the distributional tails—rare categories are merged into the reference bin, promoting stable estimation while preserving model identifiability.

To capture changes in revision patterns, we introduce two extra set of features: 
1) $f(\widetilde{Y}_{i(t-1)(l+1)}, f(\widetilde{Y}_{i(t-7)(l+7)} $ which are the most recent revision for the reference date 1 day and 7 days ago, which can provide extra information about how the epidemic trend changes in the near history; 2)  $(f(\widetilde{Y}_{i(t-1)(l+1)} - f(\widetilde{Y}_{i(t-1)l_{\text{min}}}), (f(\widetilde{Y}_{i(t-7)(l+7)} - f(\widetilde{Y}_{i(t-7)l_{\text{min}}})$ how much the revision is made in the latest release for the reference date $t-1$ and $t-7$ compared to their first release.  Such a design considering the exact value of the most recent revisions and how much the revision is made compared to the first release is for Reduces noise, improve numerical stability, since the first release are usually small and noisy.

To capture changes in revision patterns, we introduce two additional sets of features. The first consists of the most recent revisions for the reference dates \( t - 1 \) and \( t - 7 \), defined as \( f(\widetilde{Y}_{i(t-1)(l+1)}) \) and \( f(\widetilde{Y}_{i(t-7)(l+7)}) \), which provide information on short-term epidemic trends. The second set measures the magnitude of revision for these same reference dates relative to their initial releases, given by \( f(\widetilde{Y}_{i(t-1)(l+1)}) - f(\widetilde{Y}_{i(t-1)l_{\text{min}}}) \) and \( f(\widetilde{Y}_{i(t-7)(l+7)}) - f(\widetilde{Y}_{i(t-7)l_{\text{min}}}) \). This design captures both the current epidemic intensity and the magnitude of revisions relative to the first report, offering insight into how strongly early reports are updated across different levels of disease activity. It also enhances numerical stability, as initial releases are typically small and highly variable.

Now, the full model can be expressed as:

\begin{align*} 
 &Q_{f(Y_{itL})|X_{itl}}^{\tau} \\
= &X_{itl} \beta^{\tau} \\
= &\beta_0^{\tau} + \mathbf{I}_{\text{first-week}(t+l)} \beta_1^{\tau} 
&& \text{(Intercept, week-of-month effect)} \\
& + \mathbf{e}_{wd(t)} \beta_{2:3}^{\tau} + \mathbf{e}_{wd(t+l)} \beta_{4:5}^{\tau}
&& \text{(Day-of-week effects)} \\
& + f(\widetilde{Y}_{itl}) \beta_6^{\tau} + \mathbf{e}_{\sqrt{\widetilde{Y}_{itl}}} \beta_{7:9}^{\tau}
&& \text{(Disease activity level)} \\
&+ \left(f(\widetilde{Y}_{i(t-1)(l+1)}) - f(\widetilde{Y}_{i(t-1)l_{\text{min}}})\right) \beta_{10}^{\tau}
&& \text{(Recent revision magnitude, \(t{-}1\))} \\
&+ \left(f(\widetilde{Y}_{i(t-7)(l+7)}) - f(\widetilde{Y}_{i(t-7)l_{\text{min}}})\right) \beta_{11}^{\tau}
&& \text{(Recent revision magnitude, \(t{-}7\))} \\
& + f(\widetilde{Y}_{i(t-1)(l+1)}) \beta_{12}^{\tau} + f(\widetilde{Y}_{i(t-7)(l+7)}) \beta_{13}^{\tau}
&& \text{(Short-term epidemic trends)}\\
\end{align*}

We estimate the coefficients by solving the following regularized quantile regression problem:
\[
\beta^{\tau} = \arg\min_{\beta} \sum_{t = s_0 - L - W}^{s_0 - L} \sum_{l = \max(l_{\min}, l - c)}^{\min(L - 1, l + c)} w_{itl} \cdot \rho_\tau \left(f(Y_{itL}) - X_{itl} \beta\right) + \lambda \|\beta\|_1.
\]

where \( \rho_\tau(\cdot) \) denotes the quantile loss function \cite{Koenker1978}, and \( \|\cdot\|_1 \) is the \( \ell_1 \)-norm.
 
The flexibility and adaptability of this framework are governed by four key hyperparameters, each influencing a different dimension of the training procedure. These hyperparameters determine how data are selected, weighted, and regularized during model estimation:

\begin{enumerate}
    \item \textbf{Regularization strength} ($\lambda$): An $\ell_1$ (Lasso) penalty is applied to the coefficient vector to promote sparsity in the model, thereby reducing overfitting and enhancing interpretability. The hyperparameter $\lambda$ controls the strength of this regularization and governs the trade-off between model complexity and fit.

    \item \textbf{Training window length} ($W$): Instead of using the entire historical dataset, we restrict training to the most recent $W$ days for which the target is available prior to the evaluation time. This temporal constraint ensures that the model focuses on recent reporting behavior while still incorporating sufficient historical information for effective training.
    
    \item \textbf{Lag padding} ($c$): Because data revision patterns vary substantially across reporting lags, we modify the regularized data revision correction framework by narrowing the lag window and training separate models for quantities reported at different lags. In theory, this is equivalent to fitting a single generalized linear model to the pooled dataset. However, this equivalence breaks down under $\ell_1$ regularization, as the lasso alters the solution space by favoring sparsity and reducing sensitivity to outliers.
    
    To estimate the quantities reported at lag $l$, we define the training set over a local neighborhood of lags, $\mathcal{L}(l, c) = \{l': l - c \leq l' \leq l + c\}$, where $c$ controls the width of the lag window. When $c > 0$, the inverse lag feature ($1/(l+1)$ ) is included to reflect lag-dependent effects across neighboring lags.
    
    Although this strategy requires fitting multiple models and incurs additional computational cost, it improves estimation accuracy by better capturing lag-specific revision dynamics under regularization.    

    \item \textbf{Decay parameter} ($\gamma$): To emphasize training examples that resemble the current epidemic context, we introduce sample-specific weights:
    \[
    w_{itl} = \exp(-\gamma \cdot D^y_{itl} \cdot D^s_{itl}),
    \]
    where $\gamma \geq 0$ controls the sharpness of the weighting scheme. The weight $w_{itl}$ is computed based on the product of two similarity measures, evaluated relative to the estimation date $s_0$:
    \begin{itemize}
        \item $D^y_{itl} = \left|f(\widetilde{Y}_{i(s_0 - l) l}) - f(\widetilde{Y}_{itl})\right|$ quantifies the difference in activity levels between the current observation and the most recent report at lag $l$, measured on the log scale.
        \item $D^s_{itl} = \left|[f(\widetilde{Y}_{i(s_0 - l) l}) - f(\widetilde{Y}_{i(s_0 - l - 7)(l + 7)})] - [f(\widetilde{Y}_{itl}) - f(\widetilde{Y}_{i(t - 7)(l + 7)})]\right|$ captures the difference in 7-day trends between the two time points.
    \end{itemize}
    Larger values of $\gamma$ place greater emphasis on samples with similar epidemic behavior, allowing the model to focus on training points most representative of current conditions.
    
\end{enumerate}


\subsection{Evaluation Metrics}
We use the Weighted Interval Score (WIS) \cite{gneiting2007strictly}, a standard metric for evaluating distributional forecasts, to quantify the distance between the forecast distribution $F$ and the target variable $Y$.
$$
    \mbox{WIS}(F, Y) = 2\sum_{\tau}\phi_{\tau}(Y-Q_Y^{\tau})
$$

where $\phi_{\tau}(x) = \tau|x|$ for $x\geq 0$ and $\phi_{\tau}(x) = (1-\tau)|x|$ for $x<0$, which is called the tilted absolute loss\cite{mcdonald2021can}. $Q_Y^{\tau}$ denotes the forecasted $\tau$th quantile of $Y$. Given a certain estimation task of $Y_{it}$ for location $i$ and reference date $t$ based on the quantities of interest that is available on date $t+l$, the WIS score can be written as 
$$
    \mbox{WIS}(F_{f(Y_{itL}|X_{itl})}, f(Y_{itL})) = 2\sum_{\tau}\phi_{\tau}(f(Y_{itL}) - Q_{f(Y_{itL}|X_{itl})}^{\tau})
$$
where the set $\{ Q_{f(Y_{itL})|X_{itl}}^{\tau} \}_{\tau}$ represents the forecast distribution over quantiles for the log-transformed target value $Y_{itL}$, where $Y_{itL}$ denotes the $L$th revision of $Y_{it}$. If only the median is forecasted, the WIS reduces to the absolute error on the log scale:
$$ \text{WIS}_{itl} = |f(Y_{itL}) - Q_{f(Y_{itL})|X_{itl}}^{0.5} |  $$

Since WIS is computed on the log scale, it adopts a symmetric perspective on relative error, ensuring scale invariance and robustness to variation in magnitude across different reference dates and locations. However, when the target value approaches zero, relative errors can become highly volatile, introducing sensitivity into the evaluation metric.

The quantity $\exp(\text{WIS}) - 1$ approximates the absolute percentage error (APE), allowing for an interpretable link between the log-scale WIS and relative error in the original scale. A smaller $\text{WIS}_{itl}$ therefore indicates a smaller relative error between the distributional forecast and the target. When only the median forecast is considered, $\exp(\text{WIS}) - 1$ coincides with the APE if the projected median is greater than or equal to the observed value, but exceeds the APE otherwise. 

It's worth pointing out that due to the introduction of regularization, WIS differs from the penalized quantile regression loss used to train our estimation models. For model evaluation, we aggregate WIS scores by averaging over all reference dates $t$ and locations $i$ while considering log-scale quantities. This approach leverages the geometric mean, which provides a more accurate assessment of positively skewed relative errors.

\subsection{Adaptive Modeling Protocol}

The correction of real-time data revisions involves repeatedly forecasting target values using epidemic quantities observed up to a given estimation date, denoted by $s_0$. At each estimation date, we simulate the real-time setting by training the model using the latest available revisions of past values. Specifically, the model is provided with the following set of inputs for a given location $i$:

{\scriptsize
\[
\begin{array}{lccccccc}
 & Y_{i,s_0,0} & Y_{i,(s_0{-}1),1} & Y_{i,(s_0{-}2),2} & \cdots & Y_{i,(s_0{-}L{+}1),(L{-}1)} & Y_{i,(s_0{-}L),L} &\cdots \\
\text{Reference date:} & s_0 & s_0{-}1 & s_0{-}2 & \cdots & s_0{-}L{+}1 & s_0{-}L &\cdots\\
\text{Revision index:} & 0\textsuperscript{th} & 1\textsuperscript{st} & 2\textsuperscript{nd} & \cdots & (L{-}1)\textsuperscript{th} & L\textsuperscript{th}&\cdots
\end{array}
\]
}

These values represent the most recent revisions of past observations that would have been available at $s_0$. For example, $Y_{i,s_0,0}$ is the initial report for reference date $s_0$, $Y_{i,(s_0{-}1),1}$ is the second revision for reference date $s_0{-}1$, and so on. As the estimation date progresses from $s_0 -1$ to $s_0$, the data revision sequence

$$ Y_{i,(s_0-L),0:L} = \{Y_{i, (s_0-L), 0}, Y_{i, (s_0-L), 1}, Y_{i, (s_0-L), 2}, \dots, Y_{i, (s_0-L), L}\} $$

is newly added to the training set, while the forecast made for the reference date $s_0{-}L$, based on the 0th through $(L{-}1)$th revisions, can now be evaluated since the target has become available. Data for reference dates $t$ such that $s_0{-}L < t \leq s_0$ continue to serve solely as input covariates to generate real-time forecasts, until their corresponding targets become available.


To select hyperparameters $(c, \lambda, \gamma)$, we perform a grid search with 3-fold cross-validation. At each combination of hyperparameter values, the training set is partitioned into three subsets; in each fold, the model is trained on two subsets and validated on the third. The process is repeated so that each subset serves once as the validation set. Validation performance is evaluated using the average WIS across all reference dates, and the hyperparameter configuration that minimizes this score is selected.


